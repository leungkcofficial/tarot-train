{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Gray Competing Risk Model Example\n",
    "\n",
    "This notebook demonstrates how to use the `r_fine_gray.py` module to:\n",
    "1. Fit a Fine-Gray model on training data\n",
    "2. Save the model\n",
    "3. Load the model and make predictions on spatial and temporal test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(os\u001b[38;5;241m.\u001b[39mgetcwd()))))\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Import the r_fine_gray module\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mr_fine_gray\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m run_baseline_cif, load_and_predict\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_yaml_file\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the project root directory to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.dirname(os.path.dirname(os.getcwd()))))\n",
    "\n",
    "# Import the r_fine_gray module\n",
    "from src.r_fine_gray import run_baseline_cif, load_and_predict\n",
    "from src.util import load_yaml_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Datasets\n",
    "\n",
    "First, let's load the training and test datasets. In this example, we'll load them from ZenML artifacts, but you can modify this to load from your preferred source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets from ZenML artifacts\n",
    "from zenml.client import Client\n",
    "\n",
    "# Load training data\n",
    "print(\"Loading training data...\")\n",
    "train_artifact = Client().get_artifact_version(\"1bc9d8ef-eb17-474d-bbb0-46f62ce033ef\")  # Replace with your artifact ID\n",
    "train_df = train_artifact.load()\n",
    "print(f\"Training data loaded with shape: {train_df.shape}\")\n",
    "\n",
    "# Load spatial test data\n",
    "print(\"Loading spatial test data...\")\n",
    "spatial_artifact = Client().get_artifact_version(\"your-spatial-test-artifact-id\")  # Replace with your artifact ID\n",
    "spatial_test_df = spatial_artifact.load()\n",
    "print(f\"Spatial test data loaded with shape: {spatial_test_df.shape}\")\n",
    "\n",
    "# Load temporal test data\n",
    "print(\"Loading temporal test data...\")\n",
    "temporal_artifact = Client().get_artifact_version(\"your-temporal-test-artifact-id\")  # Replace with your artifact ID\n",
    "temporal_test_df = temporal_artifact.load()\n",
    "print(f\"Temporal test data loaded with shape: {temporal_test_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can load the datasets from CSV files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and modify as needed for your actual data loading\n",
    "\"\"\"\n",
    "# Load datasets from CSV files\n",
    "train_df = pd.read_csv(\"path/to/train_df.csv\")\n",
    "spatial_test_df = pd.read_csv(\"path/to/spatial_test_df.csv\")\n",
    "temporal_test_df = pd.read_csv(\"path/to/temporal_test_df.csv\")\n",
    "\n",
    "print(f\"Training data loaded with shape: {train_df.shape}\")\n",
    "print(f\"Spatial test data loaded with shape: {spatial_test_df.shape}\")\n",
    "print(f\"Temporal test data loaded with shape: {temporal_test_df.shape}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Examine Data Structure\n",
    "\n",
    "Let's examine the structure of the datasets to ensure they have the required columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the training dataset\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check column names\n",
    "print(\"Training dataset columns:\")\n",
    "print(train_df.columns.tolist())\n",
    "\n",
    "# Load mapping configuration\n",
    "mapping_file = \"src/default_master_df_mapping.yml\"\n",
    "mapping = load_yaml_file(mapping_file)\n",
    "\n",
    "# Get required columns\n",
    "duration_col = mapping.get('duration')\n",
    "event_col = mapping.get('event')\n",
    "feature_cols = mapping.get('features', [])\n",
    "\n",
    "print(f\"\\nRequired columns:\")\n",
    "print(f\"Duration column: {duration_col}\")\n",
    "print(f\"Event column: {event_col}\")\n",
    "print(f\"Feature columns: {feature_cols}\")\n",
    "\n",
    "# Check for missing required columns\n",
    "required_cols = [duration_col, event_col] + feature_cols\n",
    "missing_cols = [col for col in required_cols if col not in train_df.columns]\n",
    "\n",
    "if missing_cols:\n",
    "    print(f\"\\nWARNING: Missing required columns: {missing_cols}\")\n",
    "else:\n",
    "    print(\"\\nAll required columns are present in the dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fit Fine-Gray Models on Training Data\n",
    "\n",
    "Now let's fit the Fine-Gray models on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "output_path = Path(\"./fine_gray_output\")\n",
    "output_path.mkdir(exist_ok=True)\n",
    "\n",
    "# Fit Fine-Gray models\n",
    "print(\"Fitting Fine-Gray models on training data...\")\n",
    "\n",
    "train_results = run_baseline_cif(\n",
    "    df=train_df,\n",
    "    feature_cols=feature_cols,\n",
    "    output_path=str(output_path),\n",
    "    seed=42,\n",
    "    n_threads=None,  # Auto-detect\n",
    "    silent=False\n",
    ")\n",
    "\n",
    "print(\"Model fitting completed successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Examine Training Results\n",
    "\n",
    "Let's examine the results of the model fitting on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display dialysis risks\n",
    "print(\"Dialysis risks:\")\n",
    "for risk in train_results['dialysis_risks']:\n",
    "    print(f\"  {risk['horizon_days']} days: {risk['risk_pct']:.2f}%\")\n",
    "\n",
    "# Display death risks\n",
    "print(\"\\nDeath risks:\")\n",
    "for risk in train_results['death_risks']:\n",
    "    print(f\"  {risk['horizon_days']} days: {risk['risk_pct']:.2f}%\")\n",
    "\n",
    "# Display paths to saved files\n",
    "print(\"\\nSaved files:\")\n",
    "print(f\"  Visualization: {train_results['visualization_path']}\")\n",
    "print(f\"  CSV: {train_results['csv_path']}\")\n",
    "print(f\"  Dialysis model: {train_results['model_paths']['dialysis_model']}\")\n",
    "print(f\"  Death model: {train_results['model_paths']['death_model']}\")\n",
    "print(f\"  Metadata: {train_results['model_paths']['metadata']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Display Visualization\n",
    "\n",
    "Let's display the visualization created by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the visualization\n",
    "from IPython.display import Image\n",
    "Image(filename=train_results['visualization_path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Make Predictions on Test Datasets\n",
    "\n",
    "Now let's load the saved models and make predictions on the spatial and temporal test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get paths to saved models\n",
    "dialysis_model_path = train_results['model_paths']['dialysis_model']\n",
    "death_model_path = train_results['model_paths']['death_model']\n",
    "\n",
    "# Define time horizons\n",
    "time_horizons = [365, 730, 1095, 1460, 1825]  # 1-5 years\n",
    "\n",
    "# Predict on spatial test dataset\n",
    "print(\"Predicting on spatial test dataset...\")\n",
    "\n",
    "spatial_dialysis_predictions = load_and_predict(\n",
    "    model_path=dialysis_model_path,\n",
    "    df=spatial_test_df,\n",
    "    feature_cols=feature_cols,\n",
    "    time_horizons=time_horizons,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "spatial_death_predictions = load_and_predict(\n",
    "    model_path=death_model_path,\n",
    "    df=spatial_test_df,\n",
    "    feature_cols=feature_cols,\n",
    "    time_horizons=time_horizons,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Calculate mean risks for spatial test dataset\n",
    "spatial_dialysis_risks = spatial_dialysis_predictions.mean() * 100\n",
    "spatial_death_risks = spatial_death_predictions.mean() * 100\n",
    "\n",
    "print(\"Spatial test dataset - Dialysis risks:\")\n",
    "for horizon, risk in spatial_dialysis_risks.items():\n",
    "    days = horizon.replace('t', '')\n",
    "    print(f\"  {days} days: {risk:.2f}%\")\n",
    "\n",
    "print(\"\\nSpatial test dataset - Death risks:\")\n",
    "for horizon, risk in spatial_death_risks.items():\n",
    "    days = horizon.replace('t', '')\n",
    "    print(f\"  {days} days: {risk:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on temporal test dataset\n",
    "print(\"Predicting on temporal test dataset...\")\n",
    "\n",
    "temporal_dialysis_predictions = load_and_predict(\n",
    "    model_path=dialysis_model_path,\n",
    "    df=temporal_test_df,\n",
    "    feature_cols=feature_cols,\n",
    "    time_horizons=time_horizons,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "temporal_death_predictions = load_and_predict(\n",
    "    model_path=death_model_path,\n",
    "    df=temporal_test_df,\n",
    "    feature_cols=feature_cols,\n",
    "    time_horizons=time_horizons,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Calculate mean risks for temporal test dataset\n",
    "temporal_dialysis_risks = temporal_dialysis_predictions.mean() * 100\n",
    "temporal_death_risks = temporal_death_predictions.mean() * 100\n",
    "\n",
    "print(\"Temporal test dataset - Dialysis risks:\")\n",
    "for horizon, risk in temporal_dialysis_risks.items():\n",
    "    days = horizon.replace('t', '')\n",
    "    print(f\"  {days} days: {risk:.2f}%\")\n",
    "\n",
    "print(\"\\nTemporal test dataset - Death risks:\")\n",
    "for horizon, risk in temporal_death_risks.items():\n",
    "    days = horizon.replace('t', '')\n",
    "    print(f\"  {days} days: {risk:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Compare Risks Across Datasets\n",
    "\n",
    "Let's create a comparison table to compare the risks across the three datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract 1-year and 5-year risks\n",
    "train_dialysis_1y = train_results['dialysis_risks'][0]['risk_pct']\n",
    "train_dialysis_5y = train_results['dialysis_risks'][4]['risk_pct']\n",
    "train_death_1y = train_results['death_risks'][0]['risk_pct']\n",
    "train_death_5y = train_results['death_risks'][4]['risk_pct']\n",
    "\n",
    "spatial_dialysis_1y = spatial_dialysis_risks['t365']\n",
    "spatial_dialysis_5y = spatial_dialysis_risks['t1825']\n",
    "spatial_death_1y = spatial_death_risks['t365']\n",
    "spatial_death_5y = spatial_death_risks['t1825']\n",
    "\n",
    "temporal_dialysis_1y = temporal_dialysis_risks['t365']\n",
    "temporal_dialysis_5y = temporal_dialysis_risks['t1825']\n",
    "temporal_death_1y = temporal_death_risks['t365']\n",
    "temporal_death_5y = temporal_death_risks['t1825']\n",
    "\n",
    "# Create comparison DataFrame\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Dataset': ['Train', 'Spatial Test', 'Temporal Test'],\n",
    "    'Dialysis 1-year (%)': [train_dialysis_1y, spatial_dialysis_1y, temporal_dialysis_1y],\n",
    "    'Dialysis 5-year (%)': [train_dialysis_5y, spatial_dialysis_5y, temporal_dialysis_5y],\n",
    "    'Death 1-year (%)': [train_death_1y, spatial_death_1y, temporal_death_1y],\n",
    "    'Death 5-year (%)': [train_death_5y, spatial_death_5y, temporal_death_5y]\n",
    "})\n",
    "\n",
    "# Display comparison table\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save comparison table to CSV\n",
    "comparison_df.to_csv(output_path / \"risk_comparison.csv\", index=False)\n",
    "print(f\"Comparison table saved to {output_path / 'risk_comparison.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualize Comparison\n",
    "\n",
    "Let's create a bar chart to visualize the comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bar chart to visualize the comparison\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Dialysis risks\n",
    "comparison_df.plot(\n",
    "    x='Dataset',\n",
    "    y=['Dialysis 1-year (%)', 'Dialysis 5-year (%)'],\n",
    "    kind='bar',\n",
    "    ax=ax[0],\n",
    "    color=['#3366CC', '#6699FF']\n",
    ")\n",
    "ax[0].set_title('Dialysis Risks')\n",
    "ax[0].set_ylabel('Risk (%)')\n",
    "ax[0].grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Death risks\n",
    "comparison_df.plot(\n",
    "    x='Dataset',\n",
    "    y=['Death 1-year (%)', 'Death 5-year (%)'],\n",
    "    kind='bar',\n",
    "    ax=ax[1],\n",
    "    color=['#FF9933', '#FFCC99']\n",
    ")\n",
    "ax[1].set_title('Death Risks')\n",
    "ax[1].set_ylabel('Risk (%)')\n",
    "ax[1].grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_path / \"risk_comparison.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Patient-Level Predictions\n",
    "\n",
    "Finally, let's save the patient-level predictions for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save spatial test predictions\n",
    "spatial_dialysis_predictions.to_csv(output_path / \"spatial_dialysis_predictions.csv\")\n",
    "spatial_death_predictions.to_csv(output_path / \"spatial_death_predictions.csv\")\n",
    "\n",
    "# Save temporal test predictions\n",
    "temporal_dialysis_predictions.to_csv(output_path / \"temporal_dialysis_predictions.csv\")\n",
    "temporal_death_predictions.to_csv(output_path / \"temporal_death_predictions.csv\")\n",
    "\n",
    "print(\"Patient-level predictions saved successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusion\n",
    "\n",
    "In this notebook, we've demonstrated how to:\n",
    "1. Fit Fine-Gray competing risk models on training data\n",
    "2. Save the models for future use\n",
    "3. Load the models and make predictions on spatial and temporal test datasets\n",
    "4. Compare the risks across the three datasets\n",
    "\n",
    "The saved models can be reused for future predictions without having to refit them."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
