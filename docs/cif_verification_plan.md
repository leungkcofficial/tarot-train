# CIF Array Verification Plan

## Overview
This document outlines the sanity checks needed to verify the Cumulative Incidence Function (CIF) arrays generated by our ensemble models.

## Generated Predictions Summary

### DeepSurv Models (Models 1-24)
- **Shape**: `(1825, n_samples)`
- **Time points**: 1825 (daily predictions for 5 years)
- **Events**: Single event per model (Event 1 or Event 2)
- **Sample sizes**:
  - Temporal: 42,953 samples
  - Spatial: 155,042 samples

### DeepHit Models (Models 25-36)
- **Shape**: `(2, 5, n_samples)`
- **Time points**: 5 (at years 1, 2, 3, 4, 5)
- **Events**: 2 competing events
- **Sample sizes**:
  - Temporal: 42,953 samples
  - Spatial: 155,042 samples

## Sanity Checks to Perform

### 1. Value Range Checks
- **Check**: All CIF values should be between 0 and 1
- **Rationale**: CIF represents cumulative probability
- **Implementation**:
  ```python
  assert np.all(cif >= 0) and np.all(cif <= 1)
  ```

### 2. Monotonicity Check
- **Check**: CIF values should be non-decreasing over time
- **Rationale**: Cumulative incidence can only increase or stay the same
- **Implementation**:
  ```python
  # For DeepSurv: check along time axis (axis=0)
  assert np.all(np.diff(cif, axis=0) >= -1e-6)  # Allow small numerical errors
  
  # For DeepHit: check along time axis (axis=1)
  assert np.all(np.diff(cif, axis=1) >= -1e-6)
  ```

### 3. Competition Check (DeepHit only)
- **Check**: Sum of CIFs for both events should not exceed 1
- **Rationale**: Total probability of any event cannot exceed 100%
- **Implementation**:
  ```python
  cif_sum = cif[0] + cif[1]  # Sum event 1 and event 2
  assert np.all(cif_sum <= 1.0 + 1e-6)  # Allow small numerical errors
  ```

### 4. Initial Value Check
- **Check**: CIF should start near 0 at time 0
- **Rationale**: No events should have occurred at the beginning
- **Implementation**:
  ```python
  # For DeepSurv: check first time point
  assert np.mean(cif[0]) < 0.01  # Should be close to 0
  
  # For DeepHit: check first time point for both events
  assert np.mean(cif[:, 0, :]) < 0.01
  ```

### 5. Final Value Check
- **Check**: CIF at final time point should reflect realistic event rates
- **Rationale**: Event rates should match expected clinical outcomes
- **Expected ranges**:
  - Event 1 (e.g., dialysis): 5-20% over 5 years
  - Event 2 (e.g., death): 10-30% over 5 years

### 6. Shape Consistency Check
- **Check**: Verify dimensions match expected values
- **Implementation**:
  ```python
  # DeepSurv models
  assert temporal_cif.shape == (1825, 42953)
  assert spatial_cif.shape == (1825, 155042)
  
  # DeepHit models
  assert temporal_cif.shape == (2, 5, 42953)
  assert spatial_cif.shape == (2, 5, 155042)
  ```

### 7. NaN/Inf Check
- **Check**: No NaN or Inf values in predictions
- **Implementation**:
  ```python
  assert not np.any(np.isnan(cif))
  assert not np.any(np.isinf(cif))
  ```

### 8. Cross-Model Consistency
- **Check**: Models trained on same data should produce similar predictions
- **Implementation**: Compare predictions between:
  - Models with same structure but different optimization targets
  - Models with same event but different balancing methods

### 9. Time Grid Consistency (DeepSurv)
- **Check**: Verify that DeepSurv models use consistent time grids
- **Rationale**: All DeepSurv models should predict at the same time points

### 10. Patient-Level Consistency
- **Check**: For a random sample of patients, verify:
  - Predictions are consistent across similar models
  - High-risk patients have higher CIF values
  - Low-risk patients have lower CIF values

## Implementation Steps

1. **Load a sample of predictions** from each model type
2. **Run basic checks** (value range, NaN/Inf, shape)
3. **Run temporal checks** (monotonicity, initial/final values)
4. **Run competition checks** for DeepHit models
5. **Generate summary statistics** for each model
6. **Create visualization** showing:
   - CIF curves for random patients
   - Distribution of final CIF values
   - Comparison across models

## Expected Output

The verification script should produce:
1. **Summary report** with pass/fail for each check
2. **Statistics table** showing:
   - Min/max CIF values
   - Mean CIF at each time point
   - Event rates at final time
3. **Warning flags** for any anomalies
4. **Visualizations** for manual inspection

## Next Steps

After verification:
1. If all checks pass → Proceed to stacking DeepSurv models
2. If issues found → Investigate and potentially regenerate predictions
3. Document any expected deviations from ideal behavior