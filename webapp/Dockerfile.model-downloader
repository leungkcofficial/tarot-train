# Model Downloader Init Container
FROM python:3.11-slim

# Set working directory
WORKDIR /app

# Install required system packages
RUN apt-get update && apt-get install -y \
    curl \
    wget \
    unzip \
    git \
    && rm -rf /var/lib/apt/lists/*

# Install Python packages
RUN pip install --no-cache-dir \
    requests \
    boto3 \
    huggingface-hub \
    tqdm

# Copy model download scripts
COPY scripts/download_models.py ./
COPY scripts/verify_models.py ./

# Create models directory
RUN mkdir -p /app/models

# Set environment variables
ENV MODEL_PATH=/app/models
ENV PYTHONUNBUFFERED=1

# Model download script
COPY <<EOF ./download_models.py
#!/usr/bin/env python3
"""
Model downloader for TAROT CKD Risk Prediction
Downloads ensemble models from various sources (HuggingFace, AWS S3, etc.)
"""
import os
import sys
import requests
import json
from pathlib import Path
from tqdm import tqdm
import logging

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class ModelDownloader:
    def __init__(self, model_path: str = "/app/models"):
        self.model_path = Path(model_path)
        self.model_path.mkdir(parents=True, exist_ok=True)
        
    def download_file(self, url: str, filepath: Path, description: str = None) -> bool:
        """Download a file with progress bar"""
        try:
            response = requests.get(url, stream=True)
            response.raise_for_status()
            
            total_size = int(response.headers.get('content-length', 0))
            
            with open(filepath, 'wb') as file, tqdm(
                desc=description or filepath.name,
                total=total_size,
                unit='B',
                unit_scale=True,
                unit_divisor=1024,
            ) as pbar:
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        file.write(chunk)
                        pbar.update(len(chunk))
                        
            logger.info(f"Downloaded {filepath.name} ({total_size:,} bytes)")
            return True
            
        except Exception as e:
            logger.error(f"Failed to download {url}: {e}")
            return False
    
    def download_from_huggingface(self, repo_id: str, filename: str, token: str = None) -> bool:
        """Download model from HuggingFace Hub"""
        try:
            from huggingface_hub import hf_hub_download
            
            filepath = hf_hub_download(
                repo_id=repo_id,
                filename=filename,
                cache_dir=str(self.model_path / "cache"),
                token=token
            )
            
            # Move to models directory
            target_path = self.model_path / filename
            os.rename(filepath, target_path)
            logger.info(f"Downloaded {filename} from HuggingFace")
            return True
            
        except Exception as e:
            logger.error(f"Failed to download from HuggingFace: {e}")
            return False
    
    def create_model_config(self):
        """Create model configuration file"""
        config = {
            "ensemble_models": [
                {
                    "name": "deepsurv_model_1",
                    "type": "deepsurv",
                    "path": "deepsurv_1.pkl",
                    "weight": 0.3
                },
                {
                    "name": "deepsurv_model_2", 
                    "type": "deepsurv",
                    "path": "deepsurv_2.pkl",
                    "weight": 0.3
                },
                {
                    "name": "deephit_model_1",
                    "type": "deephit", 
                    "path": "deephit_1.pkl",
                    "weight": 0.2
                },
                {
                    "name": "lstm_model_1",
                    "type": "lstm",
                    "path": "lstm_1.pkl", 
                    "weight": 0.2
                }
            ],
            "feature_names": [
                "age", "gender", "egfr", "hemoglobin", "phosphate",
                "bicarbonate", "uacr", "charlson_score"
            ],
            "model_version": "1.0.0",
            "created_at": "2024-01-01T00:00:00Z"
        }
        
        config_path = self.model_path / "model_config.json"
        with open(config_path, 'w') as f:
            json.dump(config, f, indent=2)
        logger.info("Created model configuration file")
    
    def download_models(self):
        """Main download function"""
        logger.info("Starting model download...")
        
        # Model URLs (example - replace with actual URLs)
        model_urls = {
            "deepsurv_1.pkl": "https://example.com/models/deepsurv_1.pkl",
            "deepsurv_2.pkl": "https://example.com/models/deepsurv_2.pkl", 
            "deephit_1.pkl": "https://example.com/models/deephit_1.pkl",
            "lstm_1.pkl": "https://example.com/models/lstm_1.pkl"
        }
        
        # Download from environment variable URL if provided
        download_url = os.getenv('MODEL_DOWNLOAD_URL')
        if download_url:
            logger.info(f"Downloading models from: {download_url}")
            success = self.download_file(
                download_url,
                self.model_path / "models.zip",
                "Downloading model archive"
            )
            if success:
                # Extract models
                import zipfile
                with zipfile.ZipFile(self.model_path / "models.zip", 'r') as zip_ref:
                    zip_ref.extractall(self.model_path)
                logger.info("Extracted model archive")
                (self.model_path / "models.zip").unlink()  # Remove zip file
        
        # Try HuggingFace if token provided
        hf_token = os.getenv('HF_TOKEN')
        if hf_token:
            logger.info("Downloading from HuggingFace Hub...")
            self.download_from_huggingface(
                "tarot-ckd/models",
                "ensemble_models.tar.gz",
                hf_token
            )
        
        # Create model configuration
        self.create_model_config()
        
        # Create dummy models for testing if no real models available
        if not any(self.model_path.glob("*.pkl")):
            logger.warning("No model files found, creating dummy models for testing")
            self.create_dummy_models()
        
        logger.info("Model download completed")
    
    def create_dummy_models(self):
        """Create dummy model files for testing"""
        import pickle
        
        dummy_model = {"type": "dummy", "version": "1.0.0"}
        
        for model_name in ["deepsurv_1.pkl", "deepsurv_2.pkl", "deephit_1.pkl", "lstm_1.pkl"]:
            with open(self.model_path / model_name, 'wb') as f:
                pickle.dump(dummy_model, f)
            logger.info(f"Created dummy model: {model_name}")

def main():
    """Main function"""
    downloader = ModelDownloader()
    downloader.download_models()
    
    # Verify models were downloaded
    model_files = list(downloader.model_path.glob("*.pkl"))
    config_file = downloader.model_path / "model_config.json"
    
    if model_files and config_file.exists():
        logger.info(f"Model download successful! Found {len(model_files)} model files")
        sys.exit(0)
    else:
        logger.error("Model download failed!")
        sys.exit(1)

if __name__ == "__main__":
    main()
EOF

# Make script executable
RUN chmod +x download_models.py

# Default command
CMD ["python", "download_models.py"]